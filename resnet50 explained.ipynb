{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of ResNet50 Explained\n",
    "\n",
    "### This notebook explains the implemetation of ResNet50 using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Import Packages and Define Backend\n",
    "\n",
    "Keras.backend:\n",
    "Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend.\n",
    "\n",
    "The default configuration file looks like this:<br>\n",
    "{<br>\n",
    "    \"image_data_format\": \"channels_last\",<br>\n",
    "    \"epsilon\": 1e-07,<br>\n",
    "    \"floatx\": \"float32\",<br>\n",
    "    \"backend\": \"tensorflow\"<br>\n",
    "}<br>\n",
    "You can change these settings by editing $HOME/.keras/keras.json.\n",
    "\n",
    "image_data_format: String, either \"channels_last\" or \"channels_first\". It specifies which data format convention Keras will follow. (keras.backend.image_data_format() returns it.)\n",
    "\n",
    "For 2D data (e.g. image), \"channels_last\" assumes (rows, cols, channels) while \"channels_first\" assumes (channels, rows, cols).\n",
    "\n",
    "For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\n",
    "\n",
    "epsilon: Float, a numeric fuzzing constant used to avoid dividing by zero in some operations.\n",
    "\n",
    "floatx: String, \"float16\", \"float32\", or \"float64\". Default float precision.\n",
    "\n",
    "backend: String, \"tensorflow\", \"theano\", or \"cntk\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Identity Block\n",
    "There are two kinds of block in resnet: identity block and convolutional block\n",
    "\n",
    "Identity block has the following structure.\n",
    "\n",
    "<img src=\"identity_block.jpg\">\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis e.g res1a_branch2a\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    #e.g res1a_branch2a\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid',\n",
    "                     name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    #e.g bn1a_branch2a\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "       \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1), padding = 'same',\n",
    "                    name = conv_name_base + '2b',kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3,kernel_size = (1,1),strides = (1,1),padding = 'valid',\n",
    "                    name = conv_name_base + '2c',kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = layers.add([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Convolutional Block\n",
    "\n",
    "It has the following structure\n",
    "<img src=\"conv_block.jpg\">\n",
    "\n",
    "The only differece is there's convolutional layers in the shortcut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (s,s), padding='valid',\n",
    "                   name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f,f),strides = (1,1),padding='same',\n",
    "                   name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters=F3, kernel_size=(1,1),strides=(1,1), padding='valid',\n",
    "              name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3,name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters=F3,kernel_size = (1,1),strides=(s,s),padding='same',\n",
    "                       name = conv_name_base + '1',kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    \n",
    "    X_shortcut = BatchNormalization(axis=1,name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = layers.add([X_shortcut,X])\n",
    "    X = Activation('relu')(X)\n",
    "      \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.ResNet50 Summary\n",
    "\n",
    "Stage 1:<br>\n",
    "conv layer: conv1<br>\n",
    "BN layer: bn_conv1<br>\n",
    "Activation: relu<br>\n",
    "MaxPooling: kernel=(3,3), stride=(2,2)\n",
    "<br>\n",
    "Stage 2:<br>\n",
    "1 conv block: filters = [64, 64, 256]<br>\n",
    "2 identity blocks: filters = [64, 64, 256]\n",
    "<br>\n",
    "<br>\n",
    "Stage 3:<br>\n",
    "1 conv block: filters=[128,128,512]<br>\n",
    "3 identity blocks:  filters=[128,128,512]\n",
    "<br>\n",
    "<br>\n",
    "Stage 4:<br>\n",
    "1 conv block: filters=[256,256,1024]<br>\n",
    "5 identity blocks: filters=[256,256,1024]\n",
    "<br>\n",
    "<br>\n",
    "Stage 5:<br>\n",
    "1 conv block: filters=[512,512,2048]<br>\n",
    "2 identity blocks: filters=[512,512,2048]\n",
    "<br>\n",
    "<br>\n",
    "Pooling:<br>\n",
    "AvergaePooling: pool_size=(2,2)\n",
    "<br>\n",
    "<br>\n",
    "Output Layer:<br>\n",
    "FC: activation='softmax'\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape, classes_num):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "   \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D(padding=(3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    \n",
    "#     The convolutional block uses three set of filters of size [128,128,512], \n",
    "#     \"f\" is 3, \"s\" is 2 and the block is \"a\".The 3 identity blocks use three set\n",
    "#     of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n",
    "    X = convolutional_block(X,f = 3, filters=[128,128,512],stage=3,block='a',s = 2)\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage=3,block='b')\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage=3,block='c')\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage=3,block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    \n",
    "#     The convolutional block uses three set of filters of size [256, 256, 1024], \n",
    "#     \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "#     The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" \n",
    "#     is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
    "    X = convolutional_block(X,f = 3, filters=[256,256,1024],stage=4,block='a',s=2)\n",
    "    X = identity_block(X,f = 3, filters=[256,256,1024],stage=4, block='b')\n",
    "    X = identity_block(X,f = 3, filters=[256,256,1024],stage=4, block='c')\n",
    "    X = identity_block(X,f = 3, filters=[256,256,1024],stage=4, block='d')\n",
    "    X = identity_block(X,f = 3, filters=[256,256,1024],stage=4, block='e')\n",
    "    X = identity_block(X,f = 3, filters=[256,256,1024],stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    \n",
    "#     The convolutional block uses three set of filters of size [512, 512, 2048], \"f\"\n",
    "#     is 3, \"s\" is 2 and the block is \"a\".\n",
    "#     The 2 identity blocks use three set of filters of size [256, 256, 2048], \"f\" \n",
    "#     is 3 and the blocks are \"b\" and \"c\".\n",
    "    X = convolutional_block(X,f=3,filters=[512,512,2048],stage=5,block='a',s=2)\n",
    "    X = identity_block(X, f=3, filters=[256,256,2048],stage=5,block='b')\n",
    "    X = identity_block(X, f=3, filters=[256,256,2048],stage=5,block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    # The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n",
    "    X = AveragePooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "     \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Model Building and Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    input_shape = (64,64,3)\n",
    "    class_num = 10\n",
    "    resnet_model = ResNet50(input_shape, class_num)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train, epochs = 20, batch_size = 32)\n",
    "    preds = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Notes\n",
    "This is a simplified version of ResNet50 with random initial weights. To use pre-trained weights, please refer to [fchollet's Github](https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py). Pre-trained weights can also be found in [fchollet's releases](https://github.com/fchollet/deep-learning-models/releases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. [fchollet's Implementation of ResNet50](https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py)\n",
    "2. [deeplearning.ai-CNN作业-ResNet实现](https://zhuanlan.zhihu.com/p/31820167)\n",
    "3. [使用keras搭建残差网络](https://zhuanlan.zhihu.com/p/31820167)\n",
    "4. [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
